{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Incremental Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "da9HHn115S_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR100\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P2sc6e2p55a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "76cbe139-d051-4b27-b67c-fb0cb5c02e0f"
      },
      "source": [
        "!git clone https://github.com/akamaster/pytorch_resnet_cifar10.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch_resnet_cifar10'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 81 (delta 0), reused 3 (delta 0), pack-reused 76\u001b[K\n",
            "Unpacking objects: 100% (81/81), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVp9as9g364R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_resnet_cifar10.resnet import resnet32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oynq7hkzCkvN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d3079b20-4d70-47a6-a884-bb181ed12e1c"
      },
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DEVICE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q98ViH2RCs9E",
        "colab_type": "text"
      },
      "source": [
        "# Deal with CIFAR100 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbEgt4iI50JL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyCIFAR100:\n",
        "    '''\n",
        "    https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "    100 classes containing 600 images each, 500 training images and 100 testing images per class\n",
        "    '''    \n",
        "\n",
        "    def __init__(self):\n",
        "        self.num_classes = 100\n",
        "        self.trainset, self.testset = self.get_dataset()\n",
        "\n",
        "    def get_dataset(self):\n",
        "        self.train_transform = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225]\n",
        "            )\n",
        "        ])\n",
        "        self.test_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225]\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        if not os.path.isdir('./dataset'):\n",
        "            trainset = CIFAR100('./dataset', train=True, download=True, \n",
        "                                transform=train_transform)\n",
        "            testset = CIFAR100('./dataset', train=False, download=True, \n",
        "                            transform=test_transform)\n",
        "        else:\n",
        "            trainset = CIFAR100('./dataset', train=True, transform=train_transform)\n",
        "            testset = CIFAR100('./dataset', train=False, transform=test_transform)\n",
        "\n",
        "        return trainset, testset\n",
        "\n",
        "    def sub_sample(self, sub_labels):\n",
        "        '''\n",
        "        Sub-sample a dataset, taking only those samples with label in sub_labels\n",
        "        '''\n",
        "        train_indexes = []\n",
        "        for index in range(len(self.trainset)):\n",
        "            label = self.trainset[index][1]\n",
        "            if label in sub_labels:\n",
        "                train_indexes.append(index)\n",
        "        sub_trainset = Subset(set, train_indexes)\n",
        "\n",
        "        test_indexes = []\n",
        "        for index in range(len(self.testset)):\n",
        "            label = self.testset[index][1]\n",
        "            if label in sub_labels:\n",
        "                test_indexes.append(index)\n",
        "        sub_testset = Subset(testset, test_indexes)\n",
        "\n",
        "        return sub_trainset, sub_testset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt3L3U3pVFHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar = MyCIFAR100()\n",
        "trainset, testset = cifar.sub_sample(range(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_FTNc3TVaYi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d3919121-89a2-41d2-e5b6-47a0d72867d7"
      },
      "source": [
        "len(trainset), len(testset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jU9mtGsW2zK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "test_loader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqzM5O5BCzVU",
        "colab_type": "text"
      },
      "source": [
        "# Learn new classes without any strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR0G40ykC4ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztOoG06bC-_8",
        "colab_type": "text"
      },
      "source": [
        "# Implement LwF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jptq8QIvDA4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def common_loss(outputs, labels):\n",
        "    return F.cross_entropy(outputs, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcdDEU-GST_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def distillation_loss(student_outputs, teacher_outputs):\n",
        "    return F.kl_div(\n",
        "        F.log_softmax(student_outputs / T), F.softmax(teacher_outputs / T)\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqwYCOhhDBYI",
        "colab_type": "text"
      },
      "source": [
        "# Implement iCaRL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owX7BaiLDEGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}